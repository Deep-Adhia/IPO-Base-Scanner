# üìä Data Fetching Guide

## Overview

This document explains how the IPO scanner fetches and processes data, including:
1. **Upstox Mapping CSV** - How to automatically update it
2. **Listing Day Data** - How high/low/close/volume is fetched
3. **Data Sources** - Upstox API vs NSE (jugaad-data) fallback

---

## üîÑ Upstox Mapping CSV (`ipo_upstox_mapping.csv`)

### Purpose
The mapping CSV links IPO symbols to Upstox instrument keys, which are required for Upstox API calls.

### Format
```csv
ipo_symbol,upstox_symbol,name,instrument_key,match_type
NATCAPSUQ,NATCAPSUQ,NATURAL CAPSULES LIMITED,NSE_EQ|INE936B01015,exact
```

### Automatic Update

**Script:** `update_upstox_mapping.py`

**How it works:**
1. Reads `recent_ipo_symbols.csv` to find new IPOs
2. For each new symbol, tries to find Upstox instrument key:
   - Tries `NSE_EQ|{symbol}` format first
   - Falls back to `BSE_EQ|{symbol}` if needed
   - Verifies by attempting a historical data fetch
3. Updates `ipo_upstox_mapping.csv` with new mappings

**Usage:**
```bash
python update_upstox_mapping.py
```

**Requirements:**
- `UPSTOX_ACCESS_TOKEN` in `.env` file
- `recent_ipo_symbols.csv` must exist (generated by `fetch.py`)

**When to run:**
- After fetching new IPOs with `fetch.py`
- Weekly or whenever new IPOs are listed
- Can be automated via GitHub Actions

---

## üìÖ Listing Day Data Fetching

### How It Works

**Function:** `get_listing_day_data()` in `listing_day_breakout_scanner.py`

**Process:**
1. **Data Source:** Uses `fetch_data()` from `streamlined-ipo-scanner.py`
   - Tries **Upstox API first** (if mapping exists and token available)
   - Falls back to **NSE (jugaad-data)** if Upstox fails

2. **Data Extraction:**
   ```python
   # Fetches historical data starting from listing date
   df = fetch_data(symbol, listing_date)
   
   # Finds the listing day row
   listing_day_data = df[df['DATE'] == listing_date]
   
   # Extracts metrics
   listing_day_high = listing_day_data['HIGH'].iloc[0]
   listing_day_low = listing_day_data['LOW'].iloc[0]
   listing_day_close = listing_day_data['CLOSE'].iloc[0]
   listing_day_volume = listing_day_data['VOLUME'].iloc[0]
   ```

3. **Storage:** Saved to `ipo_listing_data.csv`

### Automatic Update

**Function:** `update_listing_data_for_new_ipos()`

**When it runs:**
- Automatically called when `listing_day_breakout_scanner.py` runs
- Checks for new IPOs in `recent_ipo_symbols.csv`
- Fetches listing day data for any missing symbols

**Manual trigger:**
```python
from listing_day_breakout_scanner import update_listing_data_for_new_ipos
update_listing_data_for_new_ipos()
```

---

## üîÑ Data Source Priority

### For Historical Daily Data (Consolidation & Listing Day Scanners)

1. **Upstox API** (Primary)
   - **Requires:** `UPSTOX_ACCESS_TOKEN` + symbol in `ipo_upstox_mapping.csv`
   - **Advantages:** Fast, reliable, premium data
   - **Fallback:** If token missing or symbol not in mapping ‚Üí NSE

2. **NSE (jugaad-data)** (Fallback)
   - **Library:** `jugaad_data.nse.history`
   - **Function:** `stock_df(symbol, from_date, to_date, series="EQ")`
   - **Advantages:** Free, no API key needed
   - **Limitations:** Rate limiting, may have delays

### For Intraday Data (Watchlist Scanner)

**Only Upstox API:**
- No fallback available
- Requires `UPSTOX_ACCESS_TOKEN` + mapping
- Fetches 5-minute candles for intraday breakouts

---

## üìã Data Flow Diagram

```
New IPO Listed
    ‚Üì
fetch.py ‚Üí recent_ipo_symbols.csv
    ‚Üì
update_upstox_mapping.py ‚Üí ipo_upstox_mapping.csv (if Upstox token available)
    ‚Üì
listing_day_breakout_scanner.py runs
    ‚Üì
update_listing_data_for_new_ipos()
    ‚Üì
get_listing_day_data(symbol, listing_date)
    ‚Üì
fetch_data() ‚Üí Tries Upstox ‚Üí Falls back to NSE
    ‚Üì
Extract HIGH, LOW, CLOSE, VOLUME from listing day
    ‚Üì
Save to ipo_listing_data.csv
```

---

## üõ†Ô∏è Maintenance Tasks

### Weekly/Monthly Tasks

1. **Update IPO List:**
   ```bash
   python fetch.py  # Updates recent_ipo_symbols.csv
   ```

2. **Update Upstox Mapping:**
   ```bash
   python update_upstox_mapping.py  # Adds new symbols to mapping
   ```

3. **Verify Listing Data:**
   - Check `ipo_listing_data.csv` for completeness
   - Missing symbols will be auto-fetched on next scanner run

### Automation (GitHub Actions)

You can add a workflow to automatically update mappings:

```yaml
name: Update Upstox Mapping
on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday at 9 AM
  workflow_dispatch:

jobs:
  update-mapping:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Update mapping
        env:
          UPSTOX_ACCESS_TOKEN: ${{ secrets.UPSTOX_ACCESS_TOKEN }}
        run: python update_upstox_mapping.py
      - name: Commit changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add ipo_upstox_mapping.csv
          git commit -m "Auto-update: Upstox mapping" || exit 0
          git push || exit 0
```

---

## ‚ùì FAQ

**Q: Do I need Upstox token?**
A: No, but it's recommended. Without it, the system uses NSE (jugaad-data) which is slower and has rate limits.

**Q: What if a symbol is not in the mapping?**
A: The system automatically falls back to NSE data. You can run `update_upstox_mapping.py` to add it.

**Q: How often should I update the mapping?**
A: Weekly or whenever new IPOs are listed. The scanner will work without it, but Upstox data is faster.

**Q: Can I use only NSE data?**
A: Yes! Just don't set `UPSTOX_ACCESS_TOKEN`. The system will use NSE for all data fetching.

**Q: What about intraday data?**
A: Currently only available via Upstox API. If you don't have a token, the watchlist scanner won't work.

---

## üìù Notes

- **Listing day data** is fetched once per IPO and stored in CSV
- **Historical data** is fetched on-demand for pattern detection
- **Intraday data** is fetched hourly for watchlist symbols
- All data fetching includes rate limiting to avoid API throttling

